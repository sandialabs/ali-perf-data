#!/bin/bash

#SBATCH --job-name=parsl.slurm.1664239390.4536815
#SBATCH --output=/global/u1/m/mcarlson/LandIce/ALITune/optimize/sampling/nrun30_greenlhs_00002/runinfo/001/submit_scripts/parsl.slurm.1664239390.4536815.submit.stdout
#SBATCH --error=/global/u1/m/mcarlson/LandIce/ALITune/optimize/sampling/nrun30_greenlhs_00002/runinfo/001/submit_scripts/parsl.slurm.1664239390.4536815.submit.stderr
#SBATCH --nodes=1
#SBATCH --time=120
#SBATCH --ntasks-per-node=1
#SBATCH --constraint=gpu
#SBATCH --ntasks-per-node=1
#SBATCH --gpus-per-node=1 --qos=regular
#SBATCH --exclusive
#SBATCH --account=m1041_g


source /global/homes/m/mcarlson/LandIce/ALITune/optimize/prepare_env.sh


export JOBNAME="parsl.slurm.1664239390.4536815"

set -e
export CORES=$(getconf _NPROCESSORS_ONLN)
[[ "1" == "1" ]] && echo "Found cores : $CORES"
WORKERCOUNT=1
FAILONANY=0
PIDS=""

CMD() {
process_worker_pool.py  --max_workers=1 -a 128.55.64.32,10.249.0.63,login23,10.252.1.51,10.249.0.91,127.0.0.1 -p 0 -c 1.0 -m None --poll 10 --task_port=54982 --result_port=54424 --logdir=/global/u1/m/mcarlson/LandIce/ALITune/optimize/sampling/nrun30_greenlhs_00002/runinfo/001/prlm_htex --block_id=1 --hb_period=30  --hb_threshold=120 --cpu-affinity none 
}
for COUNT in $(seq 1 1 $WORKERCOUNT); do
    [[ "1" == "1" ]] && echo "Launching worker: $COUNT"
    CMD $COUNT &
    PIDS="$PIDS $!"
done

ALLFAILED=1
ANYFAILED=0
for PID in $PIDS ; do
    wait $PID
    if [ "$?" != "0" ]; then
        ANYFAILED=1
    else
        ALLFAILED=0
    fi
done

[[ "1" == "1" ]] && echo "All workers done"
if [ "$FAILONANY" == "1" ]; then
    exit $ANYFAILED
else
    exit $ALLFAILED
fi

